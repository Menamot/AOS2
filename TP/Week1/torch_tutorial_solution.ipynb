{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97c68d73",
   "metadata": {},
   "source": [
    "# Introduction to pytorch models\n",
    "\n",
    "## Introduction to autodiff\n",
    "\n",
    "Load needed libraries\n",
    "$\\newcommand\\p[1]{{\\left(#1\\right)}}$\n",
    "$\\newcommand\\code[1]{\\texttt{#1}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f96377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712488e",
   "metadata": {},
   "source": [
    "Here is a simple example of how to find the minimum of the function\n",
    "$x\\mapsto\\p{x-3}^2$ using the autodiff functionality of Pytorch.\n",
    "\n",
    "First initialize a tensor `x` and indicate that we want to store a\n",
    "gradient on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b2251",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d60da9",
   "metadata": {},
   "source": [
    "Create an optimizer on parameters. Here we want to optimize w.r.t.\n",
    "variable `x`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c44b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([x], lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf264cc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Create a computational graph using parameters (here only `x`) and\n",
    "potentially other tensors.\n",
    "\n",
    "Here we only want to compute $\\p{x-3}^2$ so we define:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (x - 3) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494c2ff0",
   "metadata": {},
   "source": [
    "Back-propagating gradients for `y` down to `x`. Don't forget to\n",
    "reset gradients before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcba3fc",
   "metadata": {},
   "source": [
    "Use gradient on `x` to apply a one-step gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()\n",
    "x.grad\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c3035",
   "metadata": {},
   "source": [
    "And last we iterate the whole process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498a0955",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "it = 0\n",
    "while it < 1000:\n",
    "    loss = (x - 3) ** 2\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if it % 20 == 0:\n",
    "        print('Iteration: %d, x: %f, loss: %f' % (it, x.item(), loss.item()))\n",
    "    it += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc935ff",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Differentiate the exponential\n",
    "\n",
    "The exponential function can be approximated using its Taylor\n",
    "expansion:\n",
    "\\\\[\n",
    "\\exp\\p{z}\\approx\\sum_{k=0}^{N}\\frac{z^k}{k!}\n",
    "\\\\]\n",
    "\n",
    "First define `x`, the \"parameter\" and build a computational graph from\n",
    "it to compute the exponential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2997ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <answer>\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "exp = 0\n",
    "niter = 10\n",
    "it = 0\n",
    "fact = 1\n",
    "while it < niter:\n",
    "    exp += x ** it / fact\n",
    "    it += 1\n",
    "    fact *= it\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075cb8e0",
   "metadata": {},
   "source": [
    "Compute the gradient and verify that it is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca96dcc3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# <answer>\n",
    "exp.backward()\n",
    "print(x.grad)\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd9b253",
   "metadata": {},
   "source": [
    "## Solving equations with Pytorch\n",
    "\n",
    "Suppose we want to solve the following system of two equations\n",
    "\\\\[\n",
    "e^{-e^{-(x_1 + x_2)}} = x_2 (1 + x_1^2)\n",
    "\\\\]\n",
    "\\\\[\n",
    "x_1 \\cos(x_2) + x_2 \\sin(x_1) = 1/2\n",
    "\\\\]\n",
    "\n",
    "Find a loss whose optimization leads to a solution of the system of\n",
    "equations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef855d03",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define two functions\n",
    "# <answer>\n",
    "def f1(x1, x2):\n",
    "    return torch.exp(-torch.exp(-(x1 + x2))) - x2 * (1 + x1 ** 2)\n",
    "\n",
    "\n",
    "def f2(x1, x2):\n",
    "    return x1 * torch.cos(x2) + x2 * torch.sin(x1) - 0.5\n",
    "\n",
    "x1 = torch.tensor([0.0], requires_grad=True)\n",
    "x2 = torch.tensor([0.0], requires_grad=True)\n",
    "loss = f1(x1, x2) ** 2 + f2(x1, x2) ** 2\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5159c12a",
   "metadata": {},
   "source": [
    "Use Pytorch autodiff to solve the system of equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e422a60",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# <answer>\n",
    "optimizer = optim.SGD([x1, x2], lr=0.01)\n",
    "\n",
    "it = 0\n",
    "while it < 1000:\n",
    "    loss = f1(x1, x2) ** 2 + f2(x1, x2) ** 2\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if it % 20 == 0:\n",
    "        print('Iteration: %d, x1: %f, x2: %f, loss: %f' % (it, x1.item(), x2.item(), loss.item()))\n",
    "    it += 1\n",
    "\n",
    "f1(x1, x2).item(), f2(x1, x2).item()\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91765e1f",
   "metadata": {},
   "source": [
    "## Linear least squares Pytorch implementation\n",
    "\n",
    "Every model in Pytorch is implemented as a class that derives from\n",
    "`nn.Module`. The two main methods to implement are:\n",
    "\n",
    "- `__init__`: Declare needed building blocks to implement forward pass\n",
    "- `forward`: Implement the forward pass from the input given as\n",
    "  argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359c07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LinearLeastSquare(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LinearLeastSquare, self).__init__()\n",
    "\n",
    "        # Declaring neural networks building blocks. Here we only need\n",
    "        # a linear transform.\n",
    "        # <answer>\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "        # </answer>\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Implementing forward pass. Return corresponding output for\n",
    "        # this neural network.\n",
    "        # <answer>\n",
    "        return self.linear(input)\n",
    "        # </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc4f58",
   "metadata": {},
   "source": [
    "## Synthetic data\n",
    "\n",
    "We use the following linear model:\n",
    "\n",
    "\\\\[\n",
    "y = \\langle\\beta,x\\rangle+\\varepsilon\n",
    "\\\\]\n",
    "\n",
    "where \\\\(x\\in\\mathcal R^p\\\\) and \\\\(\\varepsilon\\sim\\mathcal N(0, \\sigma^2)\\\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6924c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "p = 512\n",
    "N = 50000\n",
    "X = torch.randn(N, p)\n",
    "beta = torch.randn(p, 1) / math.sqrt(p)\n",
    "y = torch.mm(X, beta) + 0.5 * torch.randn(N, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58380e5",
   "metadata": {},
   "source": [
    "## Preparing dataset to feed Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c0b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Gather data coming from Pytorch tensors using `TensorDataset`\n",
    "# <answer>\n",
    "dataset = TensorDataset(X, y)\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Define `train_loader` that is an iterable on mini-batches using\n",
    "# `DataLoader`\n",
    "# <answer>\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12678afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function to use\n",
    "from torch.nn import MSELoss\n",
    "# <answer>\n",
    "loss_fn = MSELoss()\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc45f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization algorithm\n",
    "from torch.optim import SGD\n",
    "\n",
    "# Instantiate model with `LinearLeastSquare` with the correct input\n",
    "# size.\n",
    "# <answer>\n",
    "model = LinearLeastSquare(p)\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b24d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the stochastic gradient descent algorithm with a learning rate of\n",
    "# 0.01 and a momentum of 0.9.\n",
    "# <answer>\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=.9)\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da27ca",
   "metadata": {},
   "source": [
    "## Learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8bfe23",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    for src, tgt in train_loader:\n",
    "        # Forward pass\n",
    "        # <answer>\n",
    "        prd = model(src)\n",
    "        # </answer>\n",
    "\n",
    "        # Backpropagation on loss\n",
    "        # <answer>\n",
    "        loss = loss_fn(prd, tgt)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # </answer>\n",
    "\n",
    "        # Gradient descent step\n",
    "        # <answer>\n",
    "        optimizer.step()\n",
    "        # </answer>\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {i}/{epochs}: Last loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e78b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(losses)) / len(losses) * epochs\n",
    "plt.plot(x, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d822990",
   "metadata": {},
   "source": [
    "From the model what should be the minimum MSE?\n",
    "<answer>\n",
    "Noise distribution is \\\\(\\varepsilon\\sim\\matcal\\p{0, 0.25}\\\\) so the\n",
    "minimum MSE should be \\\\(\\mathcal E\\p{\\epsilon^2}=0.25\\\\).\n",
    "</answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddbabfd",
   "metadata": {},
   "source": [
    "## Learning loop with scheduler\n",
    "\n",
    "From convex optimization theory the learning rate should be decreasing\n",
    "toward 0. To have something approaching we use a scheduler that is\n",
    "updating the learning rate every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba44cb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "# Define a scheduler\n",
    "# <answer>\n",
    "model = LinearLeastSquare(p)\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=.9)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[3, 6], gamma=0.2)\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7207acff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Implement the learning loop with a scheduler\n",
    "# <answer>\n",
    "epochs = 10\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    for src, tgt in train_loader:\n",
    "        # Forward pass\n",
    "        prd = model(src)\n",
    "\n",
    "        # Backpropagation on loss\n",
    "        loss = loss_fn(prd, tgt)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {i}/{epochs}: Last loss: {loss}\")\n",
    "\n",
    "x = np.arange(len(losses)) / len(losses) * epochs\n",
    "plt.plot(x, losses)\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1965560f",
   "metadata": {},
   "source": [
    "## Multi-layer perceptron\n",
    "\n",
    "Implement a multi-layer perceptron described by the following\n",
    "function:\n",
    "\\\\[\n",
    "f\\p{x,\\beta}=W_3\\sigma\\p{W_2\\sigma{W_1 x}}\n",
    "\\\\]\n",
    "where \\\\(\\sigma\\p{x}=\\max\\p{x, 0}\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc9ee3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "\n",
    "        # Define hyperparameters of neural network and building blocks\n",
    "        # <answer>\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size1 = hidden_size1\n",
    "        self.hidden_size2 = hidden_size2\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(self.hidden_size1, self.hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(self.hidden_size2, self.output_size)\n",
    "        # </answer>\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Implement forward pass\n",
    "        # <answer>\n",
    "        hidden = self.fc1(x)\n",
    "        relu1 = self.relu1(hidden)\n",
    "        hidden2 = self.fc2(relu1)\n",
    "        relu2 = self.relu2(hidden2)\n",
    "        output = self.fc3(relu2)\n",
    "        return output\n",
    "        # </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047aaeaf",
   "metadata": {},
   "source": [
    "## Synthetic 2-dimensional spiral dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "n_loops = 2\n",
    "n_samples = 1500\n",
    "\n",
    "def spirals(n_classes=3, n_samples=1500, n_loops=2):\n",
    "    klass = np.random.choice(n_classes, n_samples)\n",
    "    radius = np.random.rand(n_samples)\n",
    "    theta = klass * 2 * math.pi / n_classes + radius * 2 * math.pi * n_loops\n",
    "    radius = radius + 0.05 * np.random.randn(n_samples)\n",
    "    return np.column_stack((radius * np.cos(theta), radius * np.sin(theta))).astype(\"float32\"), klass\n",
    "\n",
    "X_, y_ = spirals(n_samples=n_samples, n_classes=n_classes, n_loops=n_loops)\n",
    "plt.scatter(X_[:, 0], X_[:, 1], c=y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757719ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "X = torch.from_numpy(X_)\n",
    "y = torch.from_numpy(y_)\n",
    "dataset = TensorDataset(X, y)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaaa8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, y_ = spirals(n_samples=1000, n_classes=n_classes, n_loops=n_loops)\n",
    "X = torch.from_numpy(X_)\n",
    "y = torch.from_numpy(y_)\n",
    "test_set = TensorDataset(X, y)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bca2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiLayerPerceptron(2, 20, 20, n_classes)\n",
    "optimizer = SGD(model.parameters(), lr=0.05)\n",
    "# optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "epochs = 1000\n",
    "losses = []\n",
    "models = []\n",
    "for i in range(epochs):\n",
    "    for src, tgt in train_loader:\n",
    "        # <answer>\n",
    "        prd = model(src)\n",
    "        loss = loss_fn(prd, tgt)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        # </answer>\n",
    "\n",
    "    # Accuracy on the test set\n",
    "    acc = 0.\n",
    "    for src, tgt in test_loader:\n",
    "        prd = model(src).detach().argmax(dim=1)\n",
    "        acc += sum(prd == tgt).item()\n",
    "\n",
    "    acc /= len(test_set)\n",
    "    print(f\"Epoch {i}/{epochs}: Test accuracy: {acc}\")\n",
    "\n",
    "    models.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520d4ae7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_image_data(model, colors, xs, ys):\n",
    "    \"\"\"Return color image of size H*W*4.\"\"\"\n",
    "\n",
    "    # Generate points in grid\n",
    "    xx, yy = np.meshgrid(xs, ys)\n",
    "    points = np.column_stack((xx.ravel(), yy.ravel())).astype(\"float32\")\n",
    "    points = torch.from_numpy(points)\n",
    "\n",
    "    # Predict class probability on points\n",
    "    prd = model(points).detach()\n",
    "    prd = torch.nn.functional.softmax(prd, dim=1)\n",
    "\n",
    "    # Build a color image from colors\n",
    "    colors = torch.from_numpy(colors)\n",
    "    img = torch.mm(prd, colors).numpy()\n",
    "    img = img.reshape((ynum, xnum, 4))\n",
    "    img = np.minimum(img, 1)\n",
    "\n",
    "    return img\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Get n_classes colors in RGBa form\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "colors = prop_cycle.by_key()[\"color\"]\n",
    "import matplotlib as mpl\n",
    "colors = mpl.colors.to_rgba_array(colors)[:n_classes, :4].astype(\"float32\")\n",
    "\n",
    "# Draw scatter plot of test set using colors\n",
    "ax.scatter(X[:, 0], X[:, 1], c=colors[y])\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ymin, ymax = ax.get_ylim()\n",
    "xnum, ynum = (int(i) for i in fig.dpi * fig.get_size_inches())\n",
    "\n",
    "# Create discretization\n",
    "xs = np.linspace(xmin, xmax, xnum)\n",
    "ys = np.linspace(ymin, ymax, ynum)\n",
    "img = get_image_data(model, colors, xs, ys)\n",
    "\n",
    "ax.imshow(img, extent=[xmin, xmax, ymin, ymax], origin=\"lower\", alpha=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <answer>\n",
    "def plot_decision_region(ax, model):\n",
    "    # Build input\n",
    "    fig = ax.get_figure()\n",
    "    xnum, ynum = (int(i) for i in fig.dpi * fig.get_size_inches())\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    xx, yy = np.meshgrid(np.linspace(xmin, xmax, xnum), np.linspace(ymin, ymax, ynum))\n",
    "    points = np.column_stack((xx.ravel(), yy.ravel())).astype(\"float32\")\n",
    "\n",
    "    points = torch.from_numpy(points)\n",
    "    prd = model(points).detach()\n",
    "\n",
    "    prd = torch.nn.functional.softmax(prd, dim=1)\n",
    "\n",
    "    prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "    colors = prop_cycle.by_key()[\"color\"]\n",
    "    import matplotlib as mpl\n",
    "    colors = torch.from_numpy(mpl.colors.to_rgba_array(colors)[:prd.size(1), :3].astype(\"float32\"))\n",
    "    img = torch.mm(prd, colors).numpy()\n",
    "\n",
    "    img = img.reshape((ynum, xnum, 3))\n",
    "\n",
    "    ax.imshow(img, extent=[xmin, xmax, ymin, ymax], zorder=0, origin=\"lower\", alpha=.7)\n",
    "    return img\n",
    "\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib as mpl\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "colors = np.array(prop_cycle.by_key()[\"color\"])[:n_classes]\n",
    "colors_rgb = mpl.colors.to_rgba_array(colors).astype(\"float32\")\n",
    "mean_color = np.minimum(np.mean(colors_rgb, axis=0), 1)\n",
    "\n",
    "X, y = spirals(n_samples=900, n_loops=n_loops, n_classes=n_classes)\n",
    "ax.scatter(X[:, 0], X[:, 1], c=colors[y])\n",
    "xnum, ynum = (int(i) for i in fig.dpi * fig.get_size_inches())\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ymin, ymax = ax.get_ylim()\n",
    "xs = np.linspace(xmin, xmax, xnum)\n",
    "ys = np.linspace(ymin, ymax, ynum)\n",
    "\n",
    "im = ax.imshow(\n",
    "    np.tile(mean_color, (ynum, xnum, 1)),\n",
    "    extent=[xmin, xmax, ymin, ymax],\n",
    "    origin=\"lower\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "def animate(i):\n",
    "    model = models[i]\n",
    "    data = get_image_data(model, colors_rgb, xs, ys)\n",
    "\n",
    "    im.set_data(data)\n",
    "    return [im]\n",
    "\n",
    "ani = animation.FuncAnimation(\n",
    "    fig=fig,\n",
    "    func=animate,\n",
    "    frames=range(len(models)),\n",
    "    interval=50,\n",
    "    blit=True\n",
    ")\n",
    "\n",
    "ani.save('test_anim.mp4', fps=50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "X, y = spirals(n_samples=900, n_loops=n_loops, n_classes=n_classes)\n",
    "\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "colors = np.array(prop_cycle.by_key()[\"color\"])\n",
    "\n",
    "ax.scatter(X[:, 0], X[:, 1], c=colors[y])\n",
    "img = plot_decision_region(ax, model)\n",
    "plt.show()\n",
    "# </answer>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
